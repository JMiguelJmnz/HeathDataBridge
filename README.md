ğŸ¥ HealthDataBridge: Healthcare ETL Pipeline to FHIR
ğŸ“Œ Project Overview
HealthDataBridge is an ETL pipeline that ingests structured healthcare datasets (e.g., CMS beneficiaries), transforms them into standardized FHIR resources, and streams them via Kafka for downstream processing.

This project demonstrates how to bridge legacy healthcare formats with modern interoperability standards like HL7 FHIR R4, leveraging streaming technologies for scalable, fault-tolerant pipelines.

ğŸ› ï¸ Tech Stack
Python

Pandas

FHIR.resources (FHIR R4 Models)

Confluent Kafka (via Docker Compose)

Docker Desktop (Zookeeper & Kafka Broker)

ğŸ“‚ Project Structure
```
HealthDataBridge/
â”œâ”€â”€ output/fhir/           # FHIR-compliant JSON output<br>
â”œâ”€â”€ scripts/<br>
â”‚   â”œâ”€â”€ beneficiary_mapper.py    # Maps CSV data to FHIR Patient
â”‚   â”œâ”€â”€ consumer_fhir.py         # Kafka consumer: JSON to FHIR output
â”‚   â”œâ”€â”€ producer_csv.py          # CSV producer: sends to Kafka
â”‚   â”œâ”€â”€ validator.py             # Validates FHIR resources
â”‚   â””â”€â”€ writer.py                # Handles FHIR JSON output
â”œâ”€â”€ docker/docker-compose.yml    # Zookeeper & Kafka services
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

ğŸ”„ Pipeline Flow

[CSV Files (CMS Beneficiaries)]
         â”‚
         â–¼
 [Kafka Producer] 
   â””â”€ Read rows
   â””â”€ Convert to JSON
   â””â”€ Send to Kafka topic
         â”‚
         â–¼
    [Kafka Topic]
         â”‚
         â–¼
 [Kafka Consumer]
   â””â”€ Convert JSON to FHIR Patient
   â””â”€ Validate resource
   â””â”€ Write FHIR JSON output


ğŸš€ Running the Project

1ï¸âƒ£ Start Kafka + Zookeeper (via Docker)
<pre>```
cd docker
docker-compose up -d
```<pre>
2ï¸âƒ£ Run Kafka Consumer
# From project root, with virtualenv activated
<pre>```python -m scripts.consumer_fhir```<pre>
3ï¸âƒ£ Run Kafka Producer (sends CSV data)
<pre>```
python -m scripts.producer_csv
```<pre>
4ï¸âƒ£ Output:
FHIR-compliant JSON files written to:
<pre>```
/output/fhir/patient_<id>.json
```<pre>


âœ… Features
Decoupled ETL pipeline via Kafka

Structured output as valid FHIR Patient R4 JSON

Extensible for additional datasets (inpatient, outpatient)

Validation layer for schema compliance

ğŸ“ˆ Future Improvements (Planned):
Integrate additional healthcare datasets (e.g., HL7 v2, CDA)

Connect output to Neo4j Knowledge Graph

Integrate with LLMs for enrichment/analysis

Orchestrate with Airflow / Dagster
